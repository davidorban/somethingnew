<!DOCTYPE html>
<html lang="hu">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Az evolúció ereje - Something New: AIs and Us</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <div class="container">
        <div class="book-header">
            <div>
                <h1>Something New: AIs and Us</h1>
            </div>
            <div class="book-nav">
                <a href="../../" class="lang-switcher">← Home</a>
                <a href="../index.html" class="lang-switcher">← All Chapters</a>
            </div>
        </div>

        <div class="book-content">
            <h2>Az evolúció ereje</h2>
        <p>Számos rémálomszerű forgatókönyv született és fejlődött ki az AGI-k, a szuperintelligens gépek felemelkedése körül regényekben és hollywoodi filmekben, de újabban formálisabb tudományos környezetben is.</p>
        <p>Melyek egy AGI cselekvési határai? Hogyan biztosíthatjuk, hogy a rendelkezésére álló erőforrások optimalizálására irányuló impulzusa, vagy az, amit saját maga számára elérhetővé tud tenni, ellenőrzés alatt maradjon?</p>
        <p>Ha az AGI-k ereje olyan nagy, mint amilyennek az előzetes elemzésből tűnik, akkor létfontosságú annak biztosítása, hogy cselekedeteik pozitívak legyenek az emberiség számára. Az általános mesterséges intelligenciák következetes, biztosított és megbízható barátsága az emberek és az emberiség egésze iránt olyan egzisztenciális kihívás, amely hatásában nem különbözik attól, amivel a dinoszauruszok néztek szembe az aszteroidájukkal szemben.</p>
        <p>Biztosak lehetünk-e abban, hogy mi mások leszünk? Tudunk-e olyan etikai rendszert tervezni, amelyet az AGI-k követni fognak, miközben olyan célokat fejlesztenek ki, amelyek túlmutatnak az eredetileg megadottakon? Elképzelhető-e olyan határok és korlátok létrehozása, amelyek cselekedeteiket bizonyos határok közé szorítják?</p>
        <p>Az ismeretlen területein, az ismert ismeretlenek és az ismeretlen ismeretlenek között, a második veszélyesebb, ha úgy hagyjuk, vagy ha a velük kapcsolatos tudatlanság állapota fennmarad. Önmagában nem egyértelmű ok a riadalomra, ha nem rendelkezünk kimerítő és megbízható válaszokkal a fenti alapvető kérdésekre. Azonban felelőtlen és helyrehozhatatlan lenne elhanyagolni a kérdések vizsgálatát, a válaszok keresését, és annak biztosítását, hogy e képességek fejlesztése ne haladjon előre a következmények mélyebb megértése nélkül.</p>
        <p>Az AGI kiszabadul a dobozból</p>
        <p>Bizonyos, potenciálisan nagyon veszélyesnek tartott technológiák biztonsági követelményei hatékony elszigetelési protokollok kidolgozásához vezettek. A rekombináns RNS-technológiák felfedezését és a génterápiák lehetőségét az 1970-es években vitatták meg az Asilomar Konferencián, amely olyan eljárásokat fogadott el, amelyekről ma már tudjuk, hogy hatékonyak voltak: az azóta eltelt negyven évben nem történt olyan biológiai baleset, amely ezekkel a technológiákkal kapcsolatos hibákkal járt volna.</p>
        <p>Nemrégiben tartottak egy Asilomar Konferenciát a Mesterséges Intelligenciáról, kifejezetten megvitatva a fejlett MI-k és AGI-k körüli lehetséges elszigetelési eljárásokat, valamint veszélyeiket és hatásaikat. Az AGI „dobozban tartása”, hogy úgy mondjam, leválasztva az internetről, korlátozva számítási erőforrásait, és biztosítva, hogy ne tudjon más erőforrásokat igénybe venni, mint amit eredetileg hozzárendeltek.</p>
        <p>10. ábra: Szakadás egy matematikai függvényen.</p>

        <div style="margin-top: 50px; padding-top: 30px; border-top: 1px solid var(--border-color); text-align: right;">
            <a href="07-ember-gep-koevolucio.html" style="color: var(--primary-color); font-weight: 600; text-decoration: none;">
                Next: Chapter 7: Ember-gép koevolúció →
            </a>
        </div>
        </div>

        <div class="footer">
            <p>&copy; 2018 David Orban</p>
            <p><a href="https://davidorban.com">davidorban.com</a></p>
        </div>
    </div>
</body>
</html>